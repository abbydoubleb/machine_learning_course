{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(f):\n",
    "    # use \";\" to separate\n",
    "    data_list = pd.read_csv(f,sep=\";\")       \n",
    "    return data_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_split(df):\n",
    "    # get the data and output\n",
    "    X = df.values[:, :-1]\n",
    "    Y = df.values[:,-1]\n",
    "\n",
    "    # do some encoding before using fit\n",
    "    # fit() does not accept Strings \n",
    "    # LabelEncoder : turn your string into incremental value\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in range(df.shape[1]-1):\n",
    "        X[:,i] = le.fit_transform(X[:,i])\n",
    "   \n",
    "    # random split data to 4 pieces, the test size is .25\n",
    "    # want to use cross validation\n",
    "    rs = ShuffleSplit(n_splits=4, test_size=.25)\n",
    "    rs_list = rs.split(X)      \n",
    "    \n",
    "    return X, Y, rs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(*data):\n",
    "    X, Y, data_index = data\n",
    "    data_index_list = list(data_index)\n",
    "    score_list = []\n",
    "    tic = time.clock()\n",
    "    \n",
    "    for train_index, test_index in data_index_list:\n",
    "        \n",
    "        cross_tic = time.clock()\n",
    "        \n",
    "        # Standardize features by removing the mean and scaling to unit variance\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X[train_index])\n",
    "        X[train_index] = scaler.transform(X[train_index])\n",
    "        X[test_index] = scaler.transform(X[test_index]) \n",
    "        \n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(15,15))\n",
    "        mlp.fit(X[train_index],Y[train_index])\n",
    "        predictions = mlp.predict(X[test_index])\n",
    "        \n",
    "        s = accuracy_score(Y[test_index],predictions)\n",
    "        score_list.append(s)\n",
    "        print(\"The cross validation score in part is {}\".format(s))\n",
    "        print(\"The training of part costs {} s\".format(time.clock()-cross_tic))\n",
    "        print(\"=====================NEXT PART=====================\")\n",
    "                \n",
    "        # the weight matrices that constitute the model parameters\n",
    "#         a = [coef.shape for coef in mlp.coefs_]\n",
    "#         print(a)\n",
    "\n",
    "    score = np.mean(score_list)\n",
    "    print(\"\\nThe prediction accuracy score of mean is {}\".format(score))\n",
    "    print('Time for training spent {} secs' .format(time.clock()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    csv_file = \"C:/Users/user/Desktop/bank-additional/bank-additional-full.csv\"\n",
    "    csv_df = read_csv(csv_file)\n",
    "    X, Y, rs_list = cross_validation_split(csv_df)\n",
    "    ANN(X, Y, rs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation score in part is 0.9143439836845684\n",
      "The training of part costs 5.6262627174305635 s\n",
      "=====================NEXT PART=====================\n",
      "The cross validation score in part is 0.91162474507138\n",
      "The training of part costs 7.7395119017387515 s\n",
      "=====================NEXT PART=====================\n",
      "The cross validation score in part is 0.9090026221229485\n",
      "The training of part costs 7.722876011127937 s\n",
      "=====================NEXT PART=====================\n",
      "The cross validation score in part is 0.9097795474410022\n",
      "The training of part costs 7.448048636697877 s\n",
      "=====================NEXT PART=====================\n",
      "\n",
      "The prediction accuracy score of mean is 0.9111877245799748\n",
      "Time for training spent 28.536897010503708 secs\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
