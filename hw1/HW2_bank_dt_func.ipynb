{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.tree import export_graphviz \n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(f):\n",
    "    # use \";\" to separate\n",
    "    data_list = pd.read_csv(f,sep=\";\")\n",
    "    return data_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_split(df):\n",
    "    # get the data and output\n",
    "    X_ori = df.values[:, :-1]\n",
    "    Y = df.values[:,-1]\n",
    "    X = np.zeros(X_ori.shape)\n",
    "\n",
    "    # do some encoding before using fit\n",
    "    # fit() does not accept Strings \n",
    "    # LabelEncoder : turn your string into incremental value\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in range(df.shape[1]-1):\n",
    "        X[:,i] = le.fit_transform(X_ori[:,i])\n",
    "\n",
    "\n",
    "    # get testdata and validation data\n",
    "    # x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3)  \n",
    "    \n",
    "    # split data to 4 pieces, the test size is .25\n",
    "    # want to use cross validation\n",
    "    rs = ShuffleSplit(n_splits=4, test_size=.25)\n",
    "    rs_list = rs.split(X)      \n",
    "    \n",
    "    return X, Y, rs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisiontree(depth, *data):\n",
    "    X, Y, data_index = data\n",
    "    \n",
    "    # data_index is generator, so list it\n",
    "    data_index_list = list(data_index)\n",
    "    \n",
    "    depth_list = range(1,depth+1)\n",
    "    test_score = []\n",
    "    \n",
    "    tic = time.clock()\n",
    "    #criterion : entropy\n",
    "    for i in depth_list:\n",
    "        clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 100, max_depth=i)\n",
    "        cross_vali_score = []\n",
    "        \n",
    "        for train_index, test_index in data_index_list:\n",
    "            \n",
    "            # the train_index is 3/4 of data, and it's random\n",
    "            # train the tree\n",
    "            clf_entropy.fit(X[train_index], Y[train_index])\n",
    "\n",
    "            #predict the output\n",
    "            y_pred_en = clf_entropy.predict(X[test_index])\n",
    "\n",
    "            #score the prediction\n",
    "            s = accuracy_score(Y[test_index],y_pred_en)*100\n",
    "            cross_vali_score.append(s)\n",
    "        \n",
    "        # mean the 4 cross validation scores\n",
    "        score = np.mean(cross_vali_score)\n",
    "        test_score.append(score)\n",
    "        del cross_vali_score\n",
    "        draw_tree(clf_entropy, i)\n",
    "        \n",
    "    cost_time = time.clock() - tic        \n",
    "    print(\"The full score is 100\")    \n",
    "    for i in depth_list:\n",
    "        print(\"The prediction accuracy score in depth {} is {}\".format(i, test_score[i-1]))\n",
    "    \n",
    "    print()\n",
    "    print('Time for training spent {} secs' .format(cost_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_tree(entropy_t, index_num):\n",
    "      \n",
    "    # Open the .dot file in a text editor\n",
    "    # Copy the piece of code and paste it @ webgraphviz.com\n",
    "    \n",
    "    export_graphviz(entropy_t, \"D:/test/entropy{}\".format(index_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    csv_file = \"C:/Users/user/Desktop/bank-additional/bank-additional-full.csv\"\n",
    "    csv_df = read_csv(csv_file)\n",
    "    X, Y, rs_list = cross_validation_split(csv_df)\n",
    "    \n",
    "    depth=10\n",
    "    decisiontree(depth, X, Y, rs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full score is 100\n",
      "The prediction accuracy score in depth 1 is 88.60104884917938\n",
      "The prediction accuracy score in depth 2 is 90.08934641157619\n",
      "The prediction accuracy score in depth 3 is 90.16218316014374\n",
      "The prediction accuracy score in depth 4 is 91.04836360104885\n",
      "The prediction accuracy score in depth 5 is 91.13819559094881\n",
      "The prediction accuracy score in depth 6 is 91.21346023113529\n",
      "The prediction accuracy score in depth 7 is 91.09934932504613\n",
      "The prediction accuracy score in depth 8 is 91.14547926580556\n",
      "The prediction accuracy score in depth 9 is 90.84684859667865\n",
      "The prediction accuracy score in depth 10 is 90.77158395649218\n",
      "\n",
      "Time for training spent 5.644827222635001 secs\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
